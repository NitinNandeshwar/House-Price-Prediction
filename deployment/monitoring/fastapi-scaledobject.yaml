apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: fastapi-latency-autoscaler
  namespace: default
spec:
  scaleTargetRef:
    name: model # update to your actual deployment name
  minReplicaCount: 1
  maxReplicaCount: 5
  pollingInterval: 30 # seconds
  cooldownPeriod: 300 # seconds before scaling down
  triggers:
  - type: prometheus
    metadata:
      serverAddress: http://prom-kube-prometheus-stackprometheus.monitoring.svc:9090
      metricName: fastapi_latency_p95
      query: |
        histogram_quantile(0.95,
        sum(rate(http_request_duration_seconds_bucket[1m])) by (le))
      threshold: "0.1"  # adjust threshold as needed

  # Add only the following to existing code
  - type: prometheus
    metadata:
      serverAddress: http://prom-kube-prometheus-stackprometheus.monitoring.svc:9090
      metricName: request_rate
      query: sum(rate(http_requests_total[1m]))
      threshold: "20"
  # For VPA Scaling based on CPU Utilization
  - type: cpu
    metricType: Utilization # Allowed types are 'Utilization' or 'AverageValue'
    metadata:
      value: "50"

  # âœ¨ New: time-based schedule with KEDA cron
  # New: run a scheduled bump on Sundays at 18:18
  - type: cron
    metadata:
      timezone: Europe/Dublin        # IANA tz
      start: "18 27 * * 0"           # 18:18 every Sunday (0 = Sunday)
      end:   "18 31 * * 0"           # end one minute later (18:19)
      desiredReplicas: "7"           # keep at least 3 during that minute
